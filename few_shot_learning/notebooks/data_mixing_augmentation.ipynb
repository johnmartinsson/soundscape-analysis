{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "social-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundata\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "\n",
    "import librosa\n",
    "import torchlibrosa\n",
    "import tqdm\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unexpected-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixAugmentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, signal_categories, noise_categories, folds=[1,2,3], augment_type=None, sample_rate=22050, \n",
    "                    window_size=2048, mel_bins=128, hop_size=512, fmin=50, fmax=11025):\n",
    "        self.augment_type = augment_type\n",
    "        self.sample_rate = sample_rate\n",
    "        \n",
    "        x = []\n",
    "        y = []\n",
    "        noise = []\n",
    "        clips = esc50.load_clips()\n",
    "        \n",
    "        for clip_id in tqdm.tqdm(dataset.clip_ids):\n",
    "            clip = clips[clip_id]\n",
    "            if clip.fold in folds:\n",
    "                waveform = clip.audio[0]\n",
    "                original_sample_rate = clip.audio[1]\n",
    "                \n",
    "                waveform = librosa.resample(\n",
    "                    waveform, \n",
    "                    original_sample_rate, \n",
    "                    sample_rate,\n",
    "                    res_type='kaiser_fast'\n",
    "                )\n",
    "                \n",
    "                self.sample_rate = clip.audio[1]\n",
    "                \n",
    "                if clip.category in noise_categories:\n",
    "                    noise.append(waveform)\n",
    "                elif clip.category in signal_categories:\n",
    "                    x.append(waveform)\n",
    "                    # set label to the index of the signal category\n",
    "                    label = np.where(signal_categories == clip.category)[0][0]\n",
    "                    y.append(label)\n",
    "                    \n",
    "        self.x = np.array(x)\n",
    "        self.y = np.array(y)\n",
    "        self.noise = np.array(noise)\n",
    "        \n",
    "        # feature extractors   \n",
    "        def logmel_extractor(z):\n",
    "            return librosa.feature.melspectrogram(\n",
    "                y          = z, \n",
    "                sr         = self.sample_rate,\n",
    "                n_mels     = mel_bins,\n",
    "                n_fft      = window_size, \n",
    "                hop_length = hop_size, \n",
    "                win_length = None, \n",
    "                window     = 'hann', \n",
    "                center     = True, \n",
    "                pad_mode   = 'reflect', \n",
    "                power      = 2.0,\n",
    "                fmin       = fmin,\n",
    "                fmax       = fmax,\n",
    "                #ref        = 1.0,\n",
    "                #amin       = 1e-10,\n",
    "                #top_db     = None\n",
    "            )\n",
    "        \n",
    "        self.logmel_extractor = logmel_extractor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        \n",
    "        if self.augment_type == 'waveform':\n",
    "            p = np.random.uniform(0.1, 0.3)\n",
    "            idx = np.random.randint(0, len(self.noise))\n",
    "            aug = self.noise[idx]\n",
    "            x_aug = (x * (1-p)) + (aug * p)\n",
    "            \n",
    "            # extract logmel after augmentation\n",
    "            x_aug = self.logmel_extractor(x_aug)\n",
    "            x_aug = np.transpose(x_aug, (1, 0))\n",
    "            x_aug = np.expand_dims(x_aug, 0)\n",
    "            \n",
    "        elif self.augment_type == 'logmel':\n",
    "            p = np.random.uniform(0.1, 0.3)\n",
    "            idx = np.random.randint(0, len(self.noise))\n",
    "            aug = self.noise[idx]\n",
    "            \n",
    "            # extract logmel before augmentation\n",
    "            x = self.logmel_extractor(x)\n",
    "            x = np.transpose(x, (1, 0))\n",
    "            x = np.expand_dims(x, 0)\n",
    "            \n",
    "            aug = self.logmel_extractor(aug)\n",
    "            aug = np.transpose(aug, (1, 0))\n",
    "            aug = np.expand_dims(aug, 0)\n",
    "            \n",
    "            x_aug = (x * (1-p)) + (aug * p)\n",
    "        else:\n",
    "            # extract logmel without augmentation\n",
    "            x_aug = self.logmel_extractor(x)\n",
    "            x_aug = np.transpose(x_aug, (1, 0))\n",
    "            x_aug = np.expand_dims(x_aug, 0)\n",
    "        return x_aug, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "disturbed-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_signal_and_noise_categories(dataset, nb_signal_categories):\n",
    "    categories = []\n",
    "    clips = dataset.load_clips()\n",
    "    clip_ids = dataset.clip_ids\n",
    "    for clip_id in clip_ids:\n",
    "        categories.append(clips[clip_id].category)\n",
    "    categories = list(set(categories))\n",
    "\n",
    "    signal_categories = np.random.choice(categories, nb_signal_categories, replace=False)\n",
    "    noise_categories = list(set(categories).difference(set(signal_categories)))\n",
    "    \n",
    "    return signal_categories, noise_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "engaging-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_function, train_loader):\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0\n",
    "    count = 0\n",
    "    for (x, y) in tqdm.tqdm(train_loader):\n",
    "        x = x.cuda()\n",
    "        y = y.type(torch.LongTensor).cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(x)['clipwise_output']\n",
    "        loss = loss_function(y_pred, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "        running_loss += loss.item()\n",
    "        count += 1\n",
    "    return running_loss / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "thorough-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loss_function, loader):\n",
    "    model.eval()\n",
    "    \n",
    "    count = 0\n",
    "    running_acc = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    ys = []\n",
    "    ys_pred_probs = []\n",
    "    for (x, y) in loader:\n",
    "        x = x.cuda()\n",
    "        y = y.type(torch.LongTensor).cuda()\n",
    "        \n",
    "        y_pred = model(x)['clipwise_output']\n",
    "        loss = loss_function(y_pred, y)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        y_pred_prob = y_pred.detach().cpu().numpy()\n",
    "        y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "        y      = y.detach().cpu().numpy().astype(np.int)\n",
    "\n",
    "        running_acc += np.mean(y==y_pred)\n",
    "        \n",
    "        count+=1\n",
    "        \n",
    "        ys.append(y)\n",
    "        ys_pred_probs.append(y_pred_prob)\n",
    "    \n",
    "    return running_loss / count, running_acc / count, np.concatenate(ys), np.concatenate(ys_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-senior",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:35<00:00, 56.84it/s]\n",
      "100%|██████████| 2000/2000 [00:11<00:00, 171.76it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 14.83it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.2728600025177004, acc: 0.15\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.93it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.2112403869628907, acc: 0.175\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.64it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.1711857318878174, acc: 0.2\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 19.06it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.1911591053009034, acc: 0.15\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 17.86it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.192969465255737, acc: 0.175\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.41it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.2193193435668945, acc: 0.1875\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 19.17it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.2349711894989013, acc: 0.15\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.32it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.189618635177612, acc: 0.1625\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.79it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.2182164669036863, acc: 0.1625\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.69it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.203043270111084, acc: 0.175\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.56it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.2104072093963625, acc: 0.2\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.89it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.216559886932373, acc: 0.1875\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.51it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.1887277126312257, acc: 0.125\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.80it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.2198331356048584, acc: 0.2\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.93it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.141807746887207, acc: 0.25\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.41it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.192142963409424, acc: 0.175\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.51it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.1690470218658446, acc: 0.225\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.62it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.229466199874878, acc: 0.1625\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.52it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.1450403213500975, acc: 0.2\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.88it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.2095767498016357, acc: 0.175\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.89it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.145741605758667, acc: 0.225\n",
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 19.11it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.167265844345093, acc: 0.225\n",
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.09it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.1488459587097166, acc: 0.2\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.76it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.1081613063812257, acc: 0.2625\n",
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.81it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.124941825866699, acc: 0.3\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.54it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.1008806943893434, acc: 0.2625\n",
      "Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 19.21it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.1931944370269774, acc: 0.225\n",
      "Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.63it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.11301646232605, acc: 0.2375\n",
      "Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.92it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.056243419647217, acc: 0.3125\n",
      "Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.98it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.0967803478240965, acc: 0.25\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.95it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.131458377838135, acc: 0.2625\n",
      "Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.54it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.070169973373413, acc: 0.275\n",
      "Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.69it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.1517130851745607, acc: 0.25\n",
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.57it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.0704947471618653, acc: 0.325\n",
      "Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.44it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.1654253005981445, acc: 0.2625\n",
      "Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.46it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.1614270210266113, acc: 0.225\n",
      "Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.61it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.183646631240845, acc: 0.1625\n",
      "Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.77it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.1265883922576903, acc: 0.275\n",
      "Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.46it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.0673206090927123, acc: 0.325\n",
      "Epoch: 39\n"
     ]
    }
   ],
   "source": [
    "# setup writer\n",
    "writer = SummaryWriter(log_dir='log_dir/no_augmentation')\n",
    "\n",
    "# setup model\n",
    "sample_rate = 22050\n",
    "window_size = 2048\n",
    "hop_size = 512\n",
    "mel_bins = 128\n",
    "fmin = 50\n",
    "fmax = sample_rate // 2\n",
    "classes_num = 10\n",
    "feature_type = 'logmel'\n",
    "\n",
    "model = models.Cnn6(sample_rate, window_size, hop_size, mel_bins, fmin, fmax, classes_num, feature_type)\n",
    "model = model.cuda()\n",
    "\n",
    "best_model = models.Cnn6(sample_rate, window_size, hop_size, mel_bins, fmin, fmax, classes_num, feature_type)\n",
    "best_model = best_model.cuda()\n",
    "\n",
    "# setup training\n",
    "learning_rate = 1e-4\n",
    "patience = 100\n",
    "epochs = 1000\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "augment_type = None\n",
    "\n",
    "# setup datasets\n",
    "esc50 = soundata.initialize('esc50')\n",
    "train_folds = [1,2,3]\n",
    "valid_folds = [4]\n",
    "test_folds = [5]\n",
    "\n",
    "signal_categories, noise_categories = random_signal_and_noise_categories(esc50, classes_num)\n",
    "\n",
    "train_dataset = MixAugmentDataset(esc50, signal_categories, noise_categories, folds=train_folds, \n",
    "                                 augment_type=augment_type, sample_rate=sample_rate,\n",
    "                                 window_size=window_size, mel_bins=mel_bins, hop_size=hop_size,\n",
    "                                 fmin=fmin, fmax=fmax)\n",
    "valid_dataset = MixAugmentDataset(esc50, signal_categories, noise_categories, folds=valid_folds, \n",
    "                                 augment_type=augment_type, sample_rate=sample_rate,\n",
    "                                 window_size=window_size, mel_bins=mel_bins, hop_size=hop_size,\n",
    "                                 fmin=fmin, fmax=fmax)\n",
    "# test_dataset = MixAugmentDataset(esc50, signal_categories, noise_categories, folds=test_folds, \n",
    "#                                 augment=augment, sample_rate=sample_rate,\n",
    "#                                 window_size=window_size, mel_bins=mel_bins, hop_size=hop_size,\n",
    "#                                 fmin=fmin, fmax=fmax)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=8)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=16, shuffle=False, num_workers=8)\n",
    "#test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=8)\n",
    "\n",
    "\n",
    "best_valid_loss = np.inf\n",
    "best_epoch = 0\n",
    "epoch = 0\n",
    "not_converged = True\n",
    "while not_converged:\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    train_loss = train(model, optimizer, loss_function, train_loader)\n",
    "    valid_loss, valid_acc, _, _ = evaluate(model, loss_function, valid_loader)\n",
    "    print(\"valid loss: {}, acc: {}\".format(valid_loss, valid_acc))\n",
    "    writer.add_scalar('loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('loss/valid', valid_loss, epoch)\n",
    "    writer.add_scalar('acc/valid', valid_acc, epoch)\n",
    "\n",
    "    epoch += 1\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        best_epoch = epoch\n",
    "        best_model.load_state_dict(model.state_dict())\n",
    "\n",
    "    # convergence criterion\n",
    "    if epoch - best_epoch >= patience or epoch > epochs:\n",
    "        not_converged = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-canada",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
